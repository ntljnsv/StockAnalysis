{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhNs218OHkbs"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "import psycopg2\n",
        "import aiohttp\n",
        "import asyncio\n",
        "import pandas as pd\n",
        "from lxml import etree\n",
        "from datetime import datetime\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VUNKCZ3Kff4"
      },
      "outputs": [],
      "source": [
        "class DatabaseHelper:\n",
        "  def __init__(self, connection_string):\n",
        "    self.connection_string = connection_string\n",
        "\n",
        "  def connect(self):\n",
        "    return psycopg2.connect(self.connection_string)\n",
        "\n",
        "  def get_latest_date(self, issuer):\n",
        "    query = \"SELECT MAX(date) FROM Day_Data WHERE issuer_name = %s\"\n",
        "    with self.connect() as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(query, issuer)\n",
        "        result = cursor.fetchone()\n",
        "    return result[0] if result and result[0] else None\n",
        "\n",
        "  def save_data(self, data):\n",
        "    query = \"\"\"\n",
        "      INSERT INTO Day_Data (issuer_name, date, last_transaction_price, max_price, min_price, avg_price, percent_change, volume, turnover, total_turnover)\n",
        "      VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
        "    \"\"\"\n",
        "    with self.connect() as conn:\n",
        "      cursor = conn.cursor()\n",
        "      cursor.executemany(query, data)\n",
        "      conn.commit()\n",
        "\n",
        "  def save_issuers(self, issuers):\n",
        "    query = \"\"\"\n",
        "        INSERT INTO Issuers (issuer_name)\n",
        "        VALUES (%s)\n",
        "        ON CONFLICT (issuer_name) DO NOTHING\n",
        "    \"\"\"\n",
        "    with self.connect() as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.executemany(query, [(issuer,) for issuer in issuers])\n",
        "        conn.commit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLBmxXzZH5eV"
      },
      "outputs": [],
      "source": [
        "class Pipeline(object):\n",
        "  def __init__(self):\n",
        "    self.filters = []\n",
        "\n",
        "  def connect(self, filter):\n",
        "    self.filters.append(filter)\n",
        "    return self\n",
        "\n",
        "  async def combine_data(self, session, url, data):\n",
        "    await self.filters[-1].process(session, url, data)\n",
        "\n",
        "  async def process_data(self, session, url, data):\n",
        "    for filter in self.filters[1:-1]:\n",
        "      data = await filter.process(session, url, data)\n",
        "    return data\n",
        "\n",
        "  async def execute(self, url, issuer_urls):\n",
        "      final_data = []\n",
        "      async with aiohttp.ClientSession() as session:\n",
        "        start_data = await self.filters[0].process(session, issuer_urls, [])\n",
        "        processing_tasks = [self.process_data(session, url, data) for data in start_data]\n",
        "        results = await asyncio.gather(*processing_tasks)\n",
        "\n",
        "        await self.combine_data(session, url, results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkqc--UhH6t9"
      },
      "outputs": [],
      "source": [
        "class Filter(object):\n",
        "  async def process(self, session, url, data):\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K-OJjkyH7v1"
      },
      "outputs": [],
      "source": [
        "class ValidIssuersFilter(Filter):\n",
        "  def __init__(self, db_helper):\n",
        "    self.db_helper = db_helper\n",
        "\n",
        "  async def get_issuers(self, session, urls):\n",
        "    issuers = []\n",
        "    async def fetch_issuers(url):\n",
        "      async with session.get(url) as response:\n",
        "        response.raise_for_status()\n",
        "        data = await response.text()\n",
        "        tree = etree.HTML(data)\n",
        "        options = tree.xpath(\"//tbody//tr//td//a\")\n",
        "        return [option.text.strip() for option in options if option.text.strip()]\n",
        "\n",
        "    results = await asyncio.gather(*[fetch_issuers(url) for url in urls])\n",
        "\n",
        "    for result in results:\n",
        "      issuers.extend(result)\n",
        "    return issuers\n",
        "\n",
        "\n",
        "  async def process(self, session, url, data):\n",
        "    issuers = await self.get_issuers(session, url)\n",
        "    pattern = re.compile(r\"^[^\\d]*$\")\n",
        "    valid_issuers = list(set([issuer for issuer in issuers if pattern.search(issuer)]))\n",
        "    self.db_helper.save_issuers(valid_issuers)\n",
        "\n",
        "    return valid_issuers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f11FPVcfH9F1"
      },
      "outputs": [],
      "source": [
        "class IssuerDatesFilter(Filter):\n",
        "  def __init__(self, db_helper):\n",
        "    self.db_helper = db_helper\n",
        "\n",
        "  def generate_date_pairs(self, latest_date):\n",
        "    now = pd.Timestamp.today().normalize()\n",
        "    pairs = []\n",
        "\n",
        "    latest_date = pd.to_datetime(latest_date).normalize()\n",
        "    start_date = latest_date + pd.Timedelta(days=1)\n",
        "    while start_date <= now.normalize():\n",
        "      end_date = min(start_date + pd.Timedelta(days=364), now)\n",
        "      pairs.append((start_date, end_date))\n",
        "      start_date = end_date + pd.Timedelta(days=1)\n",
        "    return pairs\n",
        "\n",
        "  async def process(self, session, url, data):\n",
        "    issuer_date_pairs = {}\n",
        "    latest_date = self.db_helper.get_latest_date(data)\n",
        "    if not latest_date :\n",
        "      latest_date = (pd.Timestamp.now() - pd.DateOffset(years=10)).normalize()\n",
        "\n",
        "    date_pairs = self.generate_date_pairs(latest_date)\n",
        "    issuer_date_pairs[data] = date_pairs\n",
        "    return issuer_date_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82N_x1c7H-bC"
      },
      "outputs": [],
      "source": [
        "class FillInIssuerDataFilter(Filter):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.semaphore = asyncio.Semaphore(30)\n",
        "\n",
        "  def parse_row(self, row, issuer):\n",
        "    data = [ele.strip() for ele in row]\n",
        "    if data:\n",
        "      data.insert(0, issuer)\n",
        "    return data\n",
        "\n",
        "  def parse_table(self, html_content, issuer):\n",
        "    tree = etree.HTML(html_content)\n",
        "    rows = tree.xpath(\"//tbody//tr\")\n",
        "    return [\n",
        "        self.parse_row([ele.text.strip() if ele.text else '' for ele in row.xpath(\".//td\")], issuer)\n",
        "        for row in rows\n",
        "    ]\n",
        "\n",
        "\n",
        "  async def fetch_data(self, session, url, data):\n",
        "    timeout = aiohttp.ClientTimeout(total=20)\n",
        "    retries = 8\n",
        "\n",
        "    for attempt in range(retries):\n",
        "      try:\n",
        "        async with session.post(url, data=data, timeout=timeout) as response:\n",
        "          if response.status == 200:\n",
        "            return await response.text()\n",
        "          else:\n",
        "            return None\n",
        "      except asyncio.TimeoutError:\n",
        "        pass\n",
        "      except aiohttp.ClientError as e:\n",
        "        pass\n",
        "      await asyncio.sleep(2 ** attempt + random.uniform(0, 1))\n",
        "    return None\n",
        "\n",
        "\n",
        "  async def download_data(self, session, issuer, from_date, to_date):\n",
        "    url = 'https://www.mse.mk/en/stats/symbolhistory/' + issuer\n",
        "    payload = {\n",
        "      'Code': issuer,\n",
        "      'FromDate': from_date,\n",
        "      'ToDate': to_date\n",
        "    }\n",
        "    async with self.semaphore:\n",
        "      response = await self.fetch_data(session, url, payload)\n",
        "      if response is None:\n",
        "        return None\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "  async def download_latest_issuer_data(self, session, url, issuer, date_pairs):\n",
        "    tasks = [self.download_data(session, issuer, from_date, to_date) for from_date, to_date in date_pairs]\n",
        "\n",
        "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "    valid_results = [result for result in results if result is not None]\n",
        "\n",
        "    collected_rows = []\n",
        "    loop = asyncio.get_event_loop()\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "      parsing_tasks = [\n",
        "        loop.run_in_executor(executor, self.parse_table, result, issuer)\n",
        "        for result in valid_results if result\n",
        "      ]\n",
        "      parsed_tables = await asyncio.gather(*parsing_tasks)\n",
        "\n",
        "    for data in parsed_tables:\n",
        "      if data:\n",
        "        collected_rows.extend(data)\n",
        "\n",
        "    return collected_rows\n",
        "\n",
        "\n",
        "  async def process(self, session, url, data):\n",
        "    issuer = list(data.keys())[0]\n",
        "    res = await self.download_latest_issuer_data(session, url, issuer, data[issuer])\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GFRobexH_C1"
      },
      "outputs": [],
      "source": [
        "class CombineAndSaveFilter(Filter):\n",
        "  def __init__(self, db_helper):\n",
        "    self.db_helper = db_helper\n",
        "\n",
        "  async def format_data(self, data):\n",
        "    data['date'] = pd.to_datetime(data['date'], format='%m/%d/%Y')\n",
        "\n",
        "    def transform_column(col):\n",
        "      return (\n",
        "        col.astype(str)\n",
        "        .str.replace(',', '', regex=False)\n",
        "        .apply(pd.to_numeric, errors='coerce')\n",
        "      )\n",
        "\n",
        "    numeric_cols = data.columns.difference(['issuer_name', 'date'])\n",
        "    data[numeric_cols] = data[numeric_cols].apply(transform_column)\n",
        "    data[numeric_cols] = data[numeric_cols].astype(float)\n",
        "\n",
        "    return data\n",
        "\n",
        "  async def process(self, session, url, data):\n",
        "    if not data:\n",
        "      return\n",
        "\n",
        "    col_names = [\"issuer_name\", \"date\", \"last_transaction_price\", \"max_price\", \"min_price\", \"avg_price\", \"percent_change\", \"volume\", \"turnover\", \"total_turnover\"]\n",
        "\n",
        "    data = [d for d in data if d is not None]\n",
        "    data = [sublist for group in data for sublist in group]\n",
        "\n",
        "    new_data = pd.DataFrame(data, columns=col_names)\n",
        "\n",
        "    new_data = await self.format_data(new_data)\n",
        "    new_data = new_data.dropna(axis=0, how=\"any\")\n",
        "\n",
        "    data_tuples = [tuple(x) for x in new_data.to_records(index=False)]\n",
        "\n",
        "    if data_tuples:\n",
        "      self.db_helper.save_data(data_tuples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tYCUO3PICDt"
      },
      "outputs": [],
      "source": [
        "async def main():\n",
        "  url = \"https://www.mse.mk/en/stats/symbolhistory/ADIN\"\n",
        "  issuer_urls = [\"https://www.mse.mk/en/stats/current-schedule#results-continuousTradingMode\", \"https://www.mse.mk/en/stats/current-schedule#results-fixingWith20PercentLimit\", \"https://www.mse.mk/en/stats/current-schedule#results-fixingWithoutLimit\"]\n",
        "\n",
        "  db_connection_string = os.getenv(\"DB_CONNECTION_STRING\")\n",
        "  db_helper = DatabaseHelper(db_connection_string)\n",
        "\n",
        "\n",
        "  pipeline = Pipeline()\n",
        "  pipeline.connect(ValidIssuersFilter(db_helper)) \\\n",
        "    .connect(IssuerDatesFilter(db_helper)) \\\n",
        "    .connect(FillInIssuerDataFilter()) \\\n",
        "    .connect(CombineAndSaveFilter(db_helper))\n",
        "\n",
        "  start_time = datetime.now()\n",
        "  await pipeline.execute(url, issuer_urls)\n",
        "  end_time = datetime.now()\n",
        "\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f\"Total execution time: {elapsed_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKyV16q9IEeW",
        "outputId": "9ebedf1a-e40b-4773-abb7-553dde88a933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total execution time: 0:00:51.731594\n"
          ]
        }
      ],
      "source": [
        "await main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}